{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-01T20:01:36.851027",
     "start_time": "2016-03-01T20:01:36.799167"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType, DoubleType, StringType, ArrayType, StructType, StructField\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer, VectorAssembler, Normalizer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import RandomForestClassifier, DecisionTreeClassifier, GBTClassifier\n",
    "\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.tree import GradientBoostedTrees, GradientBoostedTreesModel\n",
    "from pyspark.mllib.tree import RandomForest, RandomForestModel\n",
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "import os\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-01T20:01:39.436305",
     "start_time": "2016-03-01T20:01:39.432943"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Log Loss metric\n",
    "def logloss(df):\n",
    "    loglossRed1 =           df.map(lambda r: (r.indexedLabel, r.proba)) #probability[1]\n",
    "    \n",
    "    # Check if some proba are < 0\n",
    "    neg = loglossRed1.filter(lambda (y,p): p <= 0.0 or p >= 1.0)\n",
    "    negCount = neg.count()\n",
    "    if not negCount == 0:\n",
    "        print \"!!! There so non-valid probability !!! \" + str(negCount)\n",
    "        loglossRed1 = loglossRed1.filter(lambda (y,p): p > 0.0 and p < 1.0)\n",
    "\n",
    "    \n",
    "    loglossRed2 =  loglossRed1.map(lambda (y,p): y*log(p) + (1.0-y)*log(1.0-p))\n",
    "    loglossRed  =  loglossRed2.reduce(lambda a, b: a+b)\n",
    "    \n",
    "    return -1.0 * loglossRed / float(trainPredictions.count())\n",
    "\n",
    "#print \"Logloss on Training: \" + str(logloss(trainPredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Shrink dow extrem proba\n",
    "def shrink(val, factor = 0.2, trunc = 0.1):\n",
    "    if val < 0.0 + trunc:\n",
    "        val = 0.0 + trunc\n",
    "    elif val > 1.0 - trunc:\n",
    "        val = 1.0 - trunc\n",
    "        \n",
    "    if factor == None:\n",
    "        return val\n",
    "    \n",
    "    return val * (1.0-factor) + factor/2.0\n",
    "#print shrink(0.5)\n",
    "#print shrink(0)\n",
    "#print shrink(1)\n",
    "#print shrink(0.95)\n",
    "#print shrink(0.05)\n",
    "\n",
    "def shrinkDf(df, factor = 0.2, trunc = 0.0):\n",
    "    # proba=u'[1,null,null,[0.9413866396761132,0.05861336032388664]]\n",
    "    shrinkUdf = udf(lambda probability: shrink(float(probability.split(',')[4][:-2]), factor, trunc), DoubleType())\n",
    "    \n",
    "    dfShrink1 = df.withColumn('proba', (df.probability.cast(StringType())))\n",
    "    #print dfShrink1.take(1)\n",
    "    dfShrink = dfShrink1.withColumn('proba', shrinkUdf(dfShrink1.proba))\n",
    "    \n",
    "    return dfShrink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainPredictionsShrink = shrinkDf(trainPredictions, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "kaggleTrain = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('kaggle/train.csv')\n",
    "kaggleTrain.cache()\n",
    "print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "kaggleTest = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('kaggle/test.csv')\n",
    "kaggleTest.cache()\n",
    "print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Train count: 114321\n",
      "Kaggle Test count:  114393\n"
     ]
    }
   ],
   "source": [
    "print \"Kaggle Train count: \" + str(kaggleTrain.count())\n",
    "print \"Kaggle Test count:  \" + str(kaggleTest.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have the ID columns, type: IntegerType\n",
      "We have the target columns, type: IntegerType\n",
      "\n",
      "StringType 19\n",
      "DoubleType 108\n",
      "IntegerType 4\n"
     ]
    }
   ],
   "source": [
    "#print train.schema.fields\n",
    "columnsDict = {}\n",
    "for col in kaggleTrain.schema.fields:\n",
    "    typeKey = str(col.dataType)\n",
    "    colName = col.name\n",
    "    \n",
    "    if colName == 'ID':\n",
    "        print \"We have the ID columns, type: \" + typeKey\n",
    "        continue\n",
    "    if colName == 'target':\n",
    "        print \"We have the target columns, type: \" + typeKey\n",
    "        continue\n",
    "    \n",
    "    if typeKey not in columnsDict:\n",
    "        columnsDict[typeKey] = [col.name]\n",
    "    else:\n",
    "        columnsDict[typeKey].append(col.name)\n",
    "\n",
    "print \"\"\n",
    "for ct, cl in columnsDict.iteritems():\n",
    "    print ct + \" \" + str(len(cl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(target_freqItems=[1, 0])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggleTrain.stat.freqItems([\"target\"]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+-----+\n",
      "|target_target|    0|    1|\n",
      "+-------------+-----+-----+\n",
      "|            1|    0|87021|\n",
      "|            0|27300|    0|\n",
      "+-------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kaggleTrain.stat.crosstab(\"target\", \"target\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split the data into train and test\n",
    "splits = kaggleTrain.randomSplit([0.6, 0.4], 1234)\n",
    "train = splits[0]\n",
    "test = splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replacementFunction(df):\n",
    "    description = df.describe()\n",
    "    \n",
    "    descriptionCol = description.collect()\n",
    "    \n",
    "    replacementDict = {}\n",
    "    for col in columnsDict['DoubleType']:\n",
    "        replacementDict[col] = descriptionCol[1][col]\n",
    "        \n",
    "    for col in columnsDict['IntegerType']:\n",
    "        replacementDict[col] = descriptionCol[1][col]\n",
    "\n",
    "    #print replacementDict\n",
    "    print \"Replacing!\"\n",
    "    return df.na.fill(replacementDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "description = train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------+-------+\n",
      "|               v10|             target|summary|\n",
      "+------------------+-------------------+-------+\n",
      "|             68428|              68479|  count|\n",
      "|1.8805752686729722| 0.7608609938813359|   mean|\n",
      "|1.3981410306820936|0.42656089711962514| stddev|\n",
      "| -9.87531659989E-7|                  0|    min|\n",
      "|     18.5339164478|                  1|    max|\n",
      "+------------------+-------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "description.select(\"v10\", \"target\", \"summary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "descriptionCol = description.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean V12 example:6.879828782575871\n"
     ]
    }
   ],
   "source": [
    "print \"Mean V12 example:\" + descriptionCol[1]['v12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean V3 example:4.142397975739431\n"
     ]
    }
   ],
   "source": [
    "columnsDict['StringType']\n",
    "print \"Mean V3 example:\" + descriptionCol[1]['v4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace Now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing!\n",
      "Replacing!\n",
      "Replacing!\n"
     ]
    }
   ],
   "source": [
    "trainWithoutNull = replacementFunction(train)\n",
    "testWithoutNull = replacementFunction(test)\n",
    "kaggleTestWithoutNull = replacementFunction(kaggleTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Repartition\n",
    "#trainWithoutNull = trainWithoutNull.repartition(20)\n",
    "#testWithoutNull = testWithoutNull.repartition(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainWithoutNull.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ID: int, v1: double, v2: double, v3: string, v4: double, v5: double, v6: double, v7: double, v8: double, v9: double, v10: double, v11: double, v12: double, v13: double, v14: double, v15: double, v16: double, v17: double, v18: double, v19: double, v20: double, v21: double, v22: string, v23: double, v24: string, v25: double, v26: double, v27: double, v28: double, v29: double, v30: string, v31: string, v32: double, v33: double, v34: double, v35: double, v36: double, v37: double, v38: int, v39: double, v40: double, v41: double, v42: double, v43: double, v44: double, v45: double, v46: double, v47: string, v48: double, v49: double, v50: double, v51: double, v52: string, v53: double, v54: double, v55: double, v56: string, v57: double, v58: double, v59: double, v60: double, v61: double, v62: int, v63: double, v64: double, v65: double, v66: string, v67: double, v68: double, v69: double, v70: double, v71: string, v72: int, v73: double, v74: string, v75: string, v76: double, v77: double, v78: double, v79: string, v80: double, v81: double, v82: double, v83: double, v84: double, v85: double, v86: double, v87: double, v88: double, v89: double, v90: double, v91: string, v92: double, v93: double, v94: double, v95: double, v96: double, v97: double, v98: double, v99: double, v100: double, v101: double, v102: double, v103: double, v104: double, v105: double, v106: double, v107: string, v108: double, v109: double, v110: string, v111: double, v112: string, v113: string, v114: double, v115: double, v116: double, v117: double, v118: double, v119: double, v120: double, v121: double, v122: double, v123: double, v124: double, v125: string, v126: double, v127: double, v128: double, v129: int, v130: double, v131: double]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainWithoutNull.cache()\n",
    "testWithoutNull.cache()\n",
    "kaggleTestWithoutNull.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Label\n",
    "labelIndexer = StringIndexer(inputCol=\"target\", outputCol=\"indexedLabel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create Feature vector\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=columnsDict[\"IntegerType\"] + columnsDict[\"DoubleType\"],\n",
    "    outputCol=\"features\")\n",
    "\n",
    "#output = assembler.transform(trainWithoutNull)\n",
    "#output.schema\n",
    "#trainFeat = trainWithoutNull.withColumn(\"label\", trainWithoutNull.target.cast(\"Double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "#featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normalizer = Normalizer(inputCol=\"features\", outputCol=\"normFeatures\", p=1.0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = RandomForest.trainClassifier(train, numClasses=2, categoricalFeaturesInfo={},\n",
    "                                     numTrees=3, featureSubsetStrategy=\"auto\",\n",
    "                                     impurity='gini', maxDepth=4, maxBins=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train a GBT model.\n",
    "gbt = RandomForestClassifier(featuresCol=\"normFeatures\", labelCol=\"indexedLabel\", numTrees=10, maxDepth=10)\n",
    "#gbt = DecisionTreeClassifier(featuresCol=\"normFeatures\", labelCol=\"indexedLabel\")\n",
    "#gbt = GBTClassifier(featuresCol=\"normFeatures\", labelCol=\"indexedLabel\", maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Chain indexer and GBT in a Pipeline\n",
    "pipeline = Pipeline(stages=[assembler, labelIndexer, normalizer, gbt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train model.  This also runs the indexer.\n",
    "model = pipeline.fit(trainWithoutNull)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassificationModel (uid=rfc_81c2a7dfc011) with 20 trees\n"
     ]
    }
   ],
   "source": [
    "print model.stages[-1] # summary only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassificationModel (uid=rfc_81c2a7dfc011) with 20 trees"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.stages[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"precision\")\n",
    "\n",
    "def evaluation(df):\n",
    "    df.stat.crosstab(\"indexedLabel\", \"prediction\").show()\n",
    "    \n",
    "    print df.select(\"prediction\", \"indexedLabel\", \"probability\").take(3) # \"rawPrediction\"\n",
    "    #print rainPredictions.select(\"prediction\", \"indexedLabel\", \"normFeatures\").take(3)\n",
    "    print \"\"\n",
    "    \n",
    "    precision = evaluator.evaluate(df)\n",
    "    print \"Precision = %g\" % (precision)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grid search\n",
    "# 5->30 * 2 with 5 folds, it takes 3 days -> precision 0.851998\n",
    "#numTrees = 29\n",
    "grid = ParamGridBuilder().addGrid(gbt.numTrees, range(5, 30)) \\\n",
    "                         .addGrid(gbt.maxDepth, range(5, 30)) \\\n",
    "                         .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cross validation\n",
    "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=grid, evaluator=evaluator, numFolds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cvModel = cv.fit(trainWithoutNull)\n",
    "cvPredictions = cvModel.transform(trainWithoutNull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----+-----+\n",
      "|indexedLabel_prediction| 1.0|  0.0|\n",
      "+-----------------------+----+-----+\n",
      "|                    1.0|6435| 9941|\n",
      "|                    0.0| 194|51909|\n",
      "+-----------------------+----+-----+\n",
      "\n",
      "[Row(prediction=0.0, indexedLabel=0.0, probability=DenseVector([0.9682, 0.0318])), Row(prediction=0.0, indexedLabel=0.0, probability=DenseVector([0.785, 0.215])), Row(prediction=0.0, indexedLabel=1.0, probability=DenseVector([0.7418, 0.2582]))]\n",
      "\n",
      "Precision = 0.851998\n"
     ]
    }
   ],
   "source": [
    "evaluation(cvPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ID: int, target: int, v1: double, v2: double, v3: string, v4: double, v5: double, v6: double, v7: double, v8: double, v9: double, v10: double, v11: double, v12: double, v13: double, v14: double, v15: double, v16: double, v17: double, v18: double, v19: double, v20: double, v21: double, v22: string, v23: double, v24: string, v25: double, v26: double, v27: double, v28: double, v29: double, v30: string, v31: string, v32: double, v33: double, v34: double, v35: double, v36: double, v37: double, v38: int, v39: double, v40: double, v41: double, v42: double, v43: double, v44: double, v45: double, v46: double, v47: string, v48: double, v49: double, v50: double, v51: double, v52: string, v53: double, v54: double, v55: double, v56: string, v57: double, v58: double, v59: double, v60: double, v61: double, v62: int, v63: double, v64: double, v65: double, v66: string, v67: double, v68: double, v69: double, v70: double, v71: string, v72: int, v73: double, v74: string, v75: string, v76: double, v77: double, v78: double, v79: string, v80: double, v81: double, v82: double, v83: double, v84: double, v85: double, v86: double, v87: double, v88: double, v89: double, v90: double, v91: string, v92: double, v93: double, v94: double, v95: double, v96: double, v97: double, v98: double, v99: double, v100: double, v101: double, v102: double, v103: double, v104: double, v105: double, v106: double, v107: string, v108: double, v109: double, v110: string, v111: double, v112: string, v113: string, v114: double, v115: double, v116: double, v117: double, v118: double, v119: double, v120: double, v121: double, v122: double, v123: double, v124: double, v125: string, v126: double, v127: double, v128: double, v129: int, v130: double, v131: double, features: vector, indexedLabel: double, normFeatures: vector, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvPredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel.bestModel.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "vars() argument must have __dict__ attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-451-f631a31646d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpprint\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcvModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbestModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: vars() argument must have __dict__ attribute"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint (vars(cvModel.bestModel.stages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testRF = cvModel.bestModel.stages[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PipelineModel' object has no attribute '_java_obj'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-482-9dd4a6413152>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcvModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbestModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'PipelineModel' object has no attribute '_java_obj'"
     ]
    }
   ],
   "source": [
    "cvModel.bestModel._java_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "trainPredictions = model.transform(trainWithoutNull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-----+-----+\n",
      "|indexedLabel_prediction|  1.0|  0.0|\n",
      "+-----------------------+-----+-----+\n",
      "|                    1.0|11014| 5362|\n",
      "|                    0.0|  267|51836|\n",
      "+-----------------------+-----+-----+\n",
      "\n",
      "[Row(prediction=0.0, indexedLabel=0.0, probability=DenseVector([0.9414, 0.0586])), Row(prediction=0.0, indexedLabel=0.0, probability=DenseVector([0.8093, 0.1907])), Row(prediction=0.0, indexedLabel=1.0, probability=DenseVector([0.564, 0.436]))]\n",
      "\n",
      "Precision = 0.9178\n"
     ]
    }
   ],
   "source": [
    "evaluation(trainPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainPredictionsShrink = shrinkDf(trainPredictions, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(probability=DenseVector([0.9414, 0.0586]), proba=0.19102935222672063),\n",
       " Row(probability=DenseVector([0.8093, 0.1907]), proba=0.2834656654502874),\n",
       " Row(probability=DenseVector([0.564, 0.436]), proba=0.4552321196246967),\n",
       " Row(probability=DenseVector([0.25, 0.75]), proba=0.6749999999999999),\n",
       " Row(probability=DenseVector([0.8599, 0.1401]), proba=0.24807094041696903)]"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainPredictionsShrink.select('probability', 'proba').take(5) #.select('proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logloss on Training: 0.368739157473\n"
     ]
    }
   ],
   "source": [
    "print \"Logloss on Training: \" + str(logloss(trainPredictionsShrink))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "testPredictions = model.transform(testWithoutNull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----+-----+\n",
      "|indexedLabel_prediction| 1.0|  0.0|\n",
      "+-----------------------+----+-----+\n",
      "|                    1.0|1331| 9593|\n",
      "|                    0.0|1331|33587|\n",
      "+-----------------------+----+-----+\n",
      "\n",
      "[Row(prediction=0.0, indexedLabel=0.0, probability=DenseVector([0.771, 0.229])), Row(prediction=0.0, indexedLabel=0.0, probability=DenseVector([0.6226, 0.3774])), Row(prediction=0.0, indexedLabel=0.0, probability=DenseVector([0.65, 0.35]))]\n",
      "\n",
      "Precision = 0.761703\n"
     ]
    }
   ],
   "source": [
    "evaluation(testPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testPredictionsShrink = shrinkDf(testPredictions, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logloss on Testing: 0.356206026244\n"
     ]
    }
   ],
   "source": [
    "print \"Logloss on Testing: \" + str(logloss(testPredictionsShrink))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make prediction and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.transform(kaggleTestWithoutNull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+----+------+\n",
      "|prediction_prediction| 1.0|   0.0|\n",
      "+---------------------+----+------+\n",
      "|                  1.0|7648|     0|\n",
      "|                  0.0|   0|106745|\n",
      "+---------------------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.stat.crosstab(\"prediction\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictionsShrink = shrinkDf(predictions, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(ID=0, proba=0.51834375),\n",
       " Row(ID=1, proba=0.21741697655700676),\n",
       " Row(ID=2, proba=0.6111387804549737)]"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionsShrink.select(\"ID\", \"proba\").take(3) # \"probability\", \"rawPrediction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputFile = \"results/prediction.csv\"\n",
    "os.system(\"rm -rf \" + outputFile)\n",
    "predictionsShrink.select(\"ID\", \"proba\").withColumnRenamed(\"proba\", \"PredictedProb\").repartition(1).write.format('com.databricks.spark.csv').option(\"header\", \"true\").save(outputFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
